{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "# ticker='BABA'  #阿里巴巴\n",
    "# ticker='BIDU'  #百度\n",
    "ticker='TCOM'  #携程\n",
    "\n",
    "start_date=\"2012-01-01\"\n",
    "end_date=\"2024-05-01\"\n",
    "\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "data.to_csv('../data/'+ticker+'_stock_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下为两层感知机为基础模型的AC训练算法（实验效果不佳）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from tqdm import tqdm\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # 定义神经网络架构\n",
    "# class ActorCritic(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, action_dim):\n",
    "#         super(ActorCritic, self).__init__()\n",
    "#         self.actor = nn.Sequential(\n",
    "#             nn.Linear(input_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, action_dim),\n",
    "#             nn.Softmax(dim=-1)\n",
    "#         )\n",
    "#         self.critic = nn.Sequential(\n",
    "#             nn.Linear(input_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         action_probs = self.actor(x)\n",
    "#         state_value = self.critic(x)\n",
    "#         return action_probs, state_value\n",
    "\n",
    "# # 自定义数据集\n",
    "# class StockDataset(Dataset):\n",
    "#     def __init__(self, csv_file, seq_length=10, end_date='2021-06-06'):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.data['datetime'] = pd.to_datetime(self.data['datetime'])\n",
    "        \n",
    "#         # 筛选训练数据\n",
    "#         self.data = self.data[self.data['datetime'] <= pd.to_datetime(end_date)]\n",
    "        \n",
    "#         self.data.set_index('datetime', inplace=True)\n",
    "#         self.features = self.data[['open', 'high', 'low', 'close', 'volume']].values\n",
    "#         self.targets = self.data['close'].values\n",
    "#         self.seq_length = seq_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data) - self.seq_length + 1\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return (torch.tensor(self.features[idx:idx+self.seq_length], dtype=torch.float32),\n",
    "#                 torch.tensor(self.targets[idx+self.seq_length-1], dtype=torch.float32))\n",
    "    \n",
    "\n",
    "# def train_AC(model, dataloader, optimizer, num_epochs, model_path):\n",
    "#     model.train()\n",
    "#     criterion = nn.MSELoss()\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     model.to(device)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_loss = 0\n",
    "#         for states, targets in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "#             states, targets = states.to(device), targets.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             action_probs, state_values = model(states)\n",
    "#             loss = criterion(state_values.squeeze(), targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             epoch_loss += loss.item()\n",
    "#         print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n",
    "\n",
    "#         # 保存模型\n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "#         print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     csv_file = '../data/BABA_stock_data.csv'\n",
    "#     model_path = '../saved_models/AC_model.pth'\n",
    "#     input_dim = 5\n",
    "#     hidden_dim = 128\n",
    "#     action_dim = 3\n",
    "#     learning_rate = 1e-4\n",
    "#     num_epochs = 10\n",
    "#     seq_length = 10 #窗口时间长度\n",
    "\n",
    "#     dataset = StockDataset(csv_file, seq_length=seq_length, end_date='2021-06-06')\n",
    "#     dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#     model = ActorCritic(input_dim, hidden_dim, action_dim)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # 加载先前训练好的模型\n",
    "#     if os.path.exists(model_path):\n",
    "#         model.load_state_dict(torch.load(model_path))\n",
    "#         print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "#     train_AC(model, dataloader, optimizer, num_epochs, model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下为LSTM为基础模型的AC训练算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增加采样与奖励函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../saved_models/ac_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 166/170: 100%|██████████| 52/52 [00:02<00:00, 25.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166, Loss: 0.12009964826015326\n",
      "Loss record saved to ../saved_models/ac_loss_record.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 167/170: 100%|██████████| 52/52 [00:01<00:00, 38.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167, Loss: 0.12017225932616454\n",
      "Loss record saved to ../saved_models/ac_loss_record.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 168/170: 100%|██████████| 52/52 [00:01<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168, Loss: 0.12018046957942155\n",
      "Loss record saved to ../saved_models/ac_loss_record.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 169/170: 100%|██████████| 52/52 [00:01<00:00, 37.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169, Loss: 0.12017775685168229\n",
      "Loss record saved to ../saved_models/ac_loss_record.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 170/170: 100%|██████████| 52/52 [00:01<00:00, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170, Loss: 0.12017997153676473\n",
      "模型存储到 ../saved_models/ac_lstm_model.pth\n",
      "Loss record saved to ../saved_models/ac_loss_record.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, BatchSampler\n",
    "\n",
    "# 定义Actor-Critic网络\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.critic = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        action_probs = self.actor(lstm_out)\n",
    "        state_value = self.critic(lstm_out)\n",
    "        return action_probs, state_value\n",
    "\n",
    "# 自定义数据集\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, csv_file, seq_length=10, end_date='2021-06-06'):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data['datetime'] = pd.to_datetime(self.data['datetime'])\n",
    "        \n",
    "        # 筛选训练数据\n",
    "        self.data = self.data[self.data['datetime'] <= pd.to_datetime(end_date)]\n",
    "        \n",
    "        self.data.set_index('datetime', inplace=True)\n",
    "        self.features = self.data[['open', 'high', 'low', 'close', 'volume']].values\n",
    "        self.targets = self.data['close'].values\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.features[idx:idx+self.seq_length], dtype=torch.float32),\n",
    "                torch.tensor(self.targets[idx+self.seq_length-1], dtype=torch.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定义奖励函数\n",
    "def calculate_returns(rewards, gamma):\n",
    "    returns = []\n",
    "    R = 0\n",
    "    for r in reversed(rewards):\n",
    "        R = r + gamma * R\n",
    "        returns.insert(0, R)\n",
    "    return returns\n",
    "\n",
    "def train_AC(model, dataloader, optimizer, num_epochs, model_path, loss_file_path, gamma=0.99):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # 加载先前的loss记录\n",
    "    if os.path.exists(loss_file_path):\n",
    "        loss_df = pd.read_csv(loss_file_path)\n",
    "        start_epoch = len(loss_df)\n",
    "    else:\n",
    "        loss_df = pd.DataFrame(columns=['epoch', 'loss'])\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        state_memory = []\n",
    "        action_memory = []\n",
    "        reward_memory = []\n",
    "        next_state_memory = []\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for states, targets in tqdm(dataloader, desc=f'Epoch {epoch+1}/{start_epoch + num_epochs}'):\n",
    "            states, targets = states.to(device), targets.to(device)\n",
    "            action_probs, state_values = model(states)\n",
    "\n",
    "            actions = torch.multinomial(action_probs, 1).squeeze().tolist()\n",
    "            action_memory.extend(actions)\n",
    "\n",
    "            reward = targets - states[:, -1, 3]  # 使用价格变化作为奖励\n",
    "            reward_memory.extend(reward.tolist())\n",
    "\n",
    "            next_states = states[:, 1:, :]  # 移动一个时间步\n",
    "            next_state_values = model(next_states)[1]\n",
    "            next_state_memory.extend(next_state_values.squeeze().tolist())\n",
    "\n",
    "            state_memory.extend(state_values.squeeze().tolist())\n",
    "\n",
    "            # 计算损失并更新模型\n",
    "            if len(reward_memory) >= seq_length:\n",
    "                rewards = calculate_returns(reward_memory, gamma)\n",
    "                rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "                state_values = torch.tensor(state_memory, dtype=torch.float32).to(device)\n",
    "                next_state_values = torch.tensor(next_state_memory, dtype=torch.float32).to(device)\n",
    "\n",
    "                advantage = rewards - state_values + gamma * next_state_values #优势函数\n",
    "\n",
    "                critic_loss = criterion(state_values, rewards)\n",
    "                action_probs_selected = action_probs.gather(1, torch.tensor(action_memory).unsqueeze(1).to(device))\n",
    "                actor_loss = -torch.mean(torch.log(action_probs_selected) * advantage)\n",
    "\n",
    "                loss = actor_loss + critic_loss\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                state_memory = []\n",
    "                action_memory = []\n",
    "                reward_memory = []\n",
    "                next_state_memory = []\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_epoch_loss}')\n",
    "\n",
    "        # 保存模型\n",
    "        if epoch % 10 == 0 or epoch == start_epoch + num_epochs -1:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"模型存储到 {model_path}\")\n",
    "\n",
    "        # 保存loss记录\n",
    "        new_loss_record = pd.DataFrame({'epoch': [epoch + 1], 'loss': [avg_epoch_loss]})\n",
    "        loss_df = pd.concat([loss_df, new_loss_record], ignore_index=True)\n",
    "        loss_df.to_csv(loss_file_path, index=False)\n",
    "        print(f\"Loss record saved to {loss_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = '../data/BABA_stock_data.csv'\n",
    "    model_path = '../saved_models/ac_lstm_model.pth'\n",
    "    loss_file_path = '../saved_models/ac_loss_record.csv'\n",
    "    input_dim = 5\n",
    "    hidden_dim = 128\n",
    "    action_dim = 3\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 5 # 150,有随时继续训练的功能，强化学习就是这点好，采样时噪声多\n",
    "    seq_length = 30\n",
    "\n",
    "    dataset = StockDataset(csv_file, seq_length=seq_length, end_date='2021-06-06')\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    batch_sampler = BatchSampler(sampler, batch_size=32, drop_last=False)\n",
    "    dataloader = DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "    model = ActorCritic(input_dim, hidden_dim, action_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 加载先前训练好的模型\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "    train_AC(model, dataloader, optimizer, num_epochs, model_path, loss_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化AC_LSTM模型性能（纯粹看看能不能跑，真实性能还是要看回测的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SequentialSampler, BatchSampler\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, BatchSampler\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, action_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.critic = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        action_probs = self.actor(lstm_out)\n",
    "        state_value = self.critic(lstm_out)\n",
    "        return action_probs, state_value\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, csv_file, seq_length=10):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data['datetime'] = pd.to_datetime(self.data['datetime'])\n",
    "        self.data.set_index('datetime', inplace=True)\n",
    "        self.features = self.data[['open', 'high', 'low', 'close', 'volume']].values\n",
    "        self.targets = self.data['close'].values\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.features[idx:idx+self.seq_length], dtype=torch.float32),\n",
    "                torch.tensor(self.targets[idx+self.seq_length-1], dtype=torch.float32))\n",
    "\n",
    "def plot_loss_curve(loss_file_path):\n",
    "    # 读取损失记录文件\n",
    "    loss_df = pd.read_csv(loss_file_path)\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_df['epoch'], loss_df['loss'], label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(csv_file, model_path, seq_length):\n",
    "    # 加载数据和模型\n",
    "    dataset = StockDataset(csv_file, seq_length=seq_length)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    batch_sampler = BatchSampler(sampler, batch_size=32, drop_last=False)\n",
    "    dataloader = DataLoader(dataset, batch_sampler=batch_sampler)\n",
    "    \n",
    "    model = ActorCritic(input_dim=5, hidden_dim=128, action_dim=3)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    \n",
    "    # 获取实际值和预测值\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for states, targets in dataloader:\n",
    "            action_probs, state_values = model(states)\n",
    "            predictions.extend(state_values.squeeze().numpy())\n",
    "            actuals.extend(targets.numpy())\n",
    "    \n",
    "    # 绘制实际值和预测值对比图\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(actuals, label='Actual Values')\n",
    "    plt.plot(predictions, label='Predicted Values')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.title('Actual vs Predicted Stock Prices')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_profit_curve(csv_file, model_path, seq_length, initial_balance=10000):\n",
    "    # 加载数据和模型\n",
    "    dataset = StockDataset(csv_file, seq_length=seq_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = ActorCritic(input_dim=5, hidden_dim=128, action_dim=3)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    \n",
    "    # 模拟交易并计算收益\n",
    "    balance = initial_balance\n",
    "    positions = 0\n",
    "    profit_curve = [balance]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for states, targets in dataloader:\n",
    "            action_probs, state_values = model(states)\n",
    "            action = torch.argmax(action_probs).item()\n",
    "            price = targets.item()\n",
    "            \n",
    "            # 根据动作执行交易\n",
    "            if action == 0:  # Buy\n",
    "                positions += 1\n",
    "                balance -= price\n",
    "            elif action == 1:  # Sell\n",
    "                positions -= 1\n",
    "                balance += price\n",
    "            \n",
    "            # 更新收益曲线\n",
    "            profit_curve.append(balance + positions * price)\n",
    "    \n",
    "    # 绘制收益曲线\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(profit_curve, label='Profit Curve')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Balance')\n",
    "    plt.title('Trading Profit Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = '../data/BABA_stock_data.csv'\n",
    "    model_path = '../saved_models/ac_lstm_model.pth'\n",
    "    loss_file_path = '../saved_models/ac_loss_record.csv'\n",
    "    seq_length = 10\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plot_loss_curve(loss_file_path)\n",
    "\n",
    "    # # 绘制预测值与实际值对比图\n",
    "    # plot_predictions(csv_file, model_path, seq_length)\n",
    "\n",
    "    # 绘制收益曲线\n",
    "    # plot_profit_curve(csv_file, model_path, seq_length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
